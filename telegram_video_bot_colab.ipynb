{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "video-bot-title"
   },
   "source": [
    "# ü§ñ Telegram Video Bot –¥–ª—è –Ω–∞—Ä–µ–∑–∫–∏ –≤–∏–¥–µ–æ –Ω–∞ —à–æ—Ç—Å—ã\n",
    "\n",
    "–≠—Ç–æ—Ç notebook –∑–∞–ø—É—Å–∫–∞–µ—Ç Telegram –±–æ—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π:\n",
    "- –°–∫–∞—á–∏–≤–∞–µ—Ç –≤–∏–¥–µ–æ —Å YouTube\n",
    "- –ù–∞—Ä–µ–∑–∞–µ—Ç –∏—Ö –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ –∫–ª–∏–ø—ã (—à–æ—Ç—Å—ã)\n",
    "- –ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–∞ Google Drive\n",
    "- –î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏\n",
    "\n",
    "## üìã –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:\n",
    "1. –¢–æ–∫–µ–Ω Telegram –±–æ—Ç–∞\n",
    "2. Google OAuth —Ç–æ–∫–µ–Ω (base64)\n",
    "3. –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å –∫–æ–¥–æ–º –Ω–∞ GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-section"
   },
   "source": [
    "## üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-system-deps"
   },
   "outputs": [],
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
    "!apt update -qq\n",
    "!apt install -y ffmpeg\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å—Ç–∞–Ω–æ–≤–∫—É ffmpeg\n",
    "!ffmpeg -version | head -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "# –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å –±–æ—Ç–æ–º\n",
    "import os\n",
    "\n",
    "# –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π\n",
    "GITHUB_REPO = \"https://github.com/YOUR_USERNAME/YOUR_REPO.git\"\n",
    "\n",
    "# –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π\n",
    "if not os.path.exists('telegram-video-bot'):\n",
    "    !git clone {GITHUB_REPO} telegram-video-bot\n",
    "else:\n",
    "    print(\"–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —É–∂–µ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω\")\n",
    "\n",
    "# –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞\n",
    "%cd telegram-video-bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-python-deps"
   },
   "outputs": [],
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Python –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ –¥–ª—è Colab\n",
    "!pip install -q python-telegram-bot==20.7\n",
    "!pip install -q yt-dlp==2023.12.30\n",
    "!pip install -q ffmpeg-python==0.2.0\n",
    "!pip install -q openai-whisper==20231117\n",
    "!pip install -q google-api-python-client==2.108.0\n",
    "!pip install -q google-auth-httplib2==0.1.1\n",
    "!pip install -q google-auth-oauthlib==1.1.0\n",
    "!pip install -q python-dotenv==1.0.0\n",
    "!pip install -q Pillow==10.1.0\n",
    "!pip install -q moviepy==1.0.3\n",
    "\n",
    "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞–∫–µ—Ç—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q nest-asyncio\n",
    "\n",
    "print(\"‚úÖ –í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-section"
   },
   "source": [
    "## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-env"
   },
   "outputs": [],
   "source": [
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω—ã –∏–∑ Colab Secrets –∏–ª–∏ –≤–≤–æ–¥–∏–º –≤—Ä—É—á–Ω—É—é\n",
    "try:\n",
    "    # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ Colab Secrets\n",
    "    TELEGRAM_BOT_TOKEN = userdata.get('TELEGRAM_BOT_TOKEN')\n",
    "    GOOGLE_OAUTH_TOKEN_BASE64 = userdata.get('GOOGLE_OAUTH_TOKEN_BASE64')\n",
    "    print(\"‚úÖ –¢–æ–∫–µ–Ω—ã –ø–æ–ª—É—á–µ–Ω—ã –∏–∑ Colab Secrets\")\nexcept:\n",
    "    # –í–≤–æ–¥ –≤—Ä—É—á–Ω—É—é\n",
    "    print(\"‚ùå –¢–æ–∫–µ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ Colab Secrets\")\n",
    "    print(\"–í–≤–µ–¥–∏—Ç–µ —Ç–æ–∫–µ–Ω—ã –≤—Ä—É—á–Ω—É—é:\")\n",
    "    \n",
    "    TELEGRAM_BOT_TOKEN = input(\"Telegram Bot Token: \")\n",
    "    GOOGLE_OAUTH_TOKEN_BASE64 = input(\"Google OAuth Token (base64): \")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º .env —Ñ–∞–π–ª\n",
    "env_content = f\"\"\"TELEGRAM_BOT_TOKEN={TELEGRAM_BOT_TOKEN}\n",
    "GOOGLE_OAUTH_TOKEN_BASE64={GOOGLE_OAUTH_TOKEN_BASE64}\n",
    "\"\"\"\n",
    "\n",
    "with open('.env', 'w') as f:\n",
    "    f.write(env_content)\n",
    "\n",
    "print(\"‚úÖ –§–∞–π–ª .env —Å–æ–∑–¥–∞–Ω\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab-secrets-info"
   },
   "source": [
    "### üîê –ö–∞–∫ –¥–æ–±–∞–≤–∏—Ç—å —Ç–æ–∫–µ–Ω—ã –≤ Colab Secrets:\n",
    "\n",
    "1. –ù–∞–∂–º–∏—Ç–µ –Ω–∞ –∏–∫–æ–Ω–∫—É üîë –≤ –ª–µ–≤–æ–π –ø–∞–Ω–µ–ª–∏ Colab\n",
    "2. –î–æ–±–∞–≤—å—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —Å–µ–∫—Ä–µ—Ç—ã:\n",
    "   - `TELEGRAM_BOT_TOKEN` - —Ç–æ–∫–µ–Ω –≤–∞—à–µ–≥–æ Telegram –±–æ—Ç–∞\n",
    "   - `GOOGLE_OAUTH_TOKEN_BASE64` - —Ç–æ–∫–µ–Ω Google OAuth –≤ —Ñ–æ—Ä–º–∞—Ç–µ base64\n",
    "\n",
    "–≠—Ç–æ –±–æ–ª–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Å–ø–æ—Å–æ–± —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run-section"
   },
   "source": [
    "## üöÄ –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-resources"
   },
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã Colab\n",
    "import torch\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "print(\"üñ•Ô∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ:\")\n",
    "print(f\"CPU —è–¥–µ—Ä: {psutil.cpu_count()}\")\n",
    "print(f\"RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB\")\n",
    "print(f\"–°–≤–æ–±–æ–¥–Ω–æ RAM: {psutil.virtual_memory().available / (1024**3):.1f} GB\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nüöÄ GPU –¥–æ—Å—Ç—É–ø–µ–Ω: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}\")\n",
    "    print(f\"GPU –ø–∞–º—è—Ç—å: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB\")\nelse:\n",
    "    print(\"\\n‚ö†Ô∏è GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏—Å–∫\n",
    "disk_usage = psutil.disk_usage('/')\n",
    "print(f\"\\nüíæ –î–∏—Å–∫: {disk_usage.free / (1024**3):.1f} GB —Å–≤–æ–±–æ–¥–Ω–æ –∏–∑ {disk_usage.total / (1024**3):.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "optimize-colab"
   },
   "outputs": [],
   "source": [
    "# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –¥–ª—è Colab\n",
    "import os\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "os.environ['OMP_NUM_THREADS'] = str(min(psutil.cpu_count(), 8))\n",
    "os.environ['MKL_NUM_THREADS'] = str(min(psutil.cpu_count(), 8))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è ffmpeg\n",
    "os.environ['FFMPEG_THREADS'] = str(min(psutil.cpu_count(), 6))\n",
    "\n",
    "print(\"‚ö° –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã:\")\n",
    "print(f\"  - CPU –ø–æ—Ç–æ–∫–∏: {os.environ['OMP_NUM_THREADS']}\")\n",
    "print(f\"  - FFmpeg –ø–æ—Ç–æ–∫–∏: {os.environ['FFMPEG_THREADS']}\")\n",
    "print(f\"  - GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {os.environ['CUDA_VISIBLE_DEVICES']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-imports"
   },
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º–ø–æ—Ä—Ç—ã\n",
    "try:\n",
    "    import telegram\n",
    "    import yt_dlp\n",
    "    import ffmpeg\n",
    "    import whisper\n",
    "    from google.oauth2.credentials import Credentials\n",
    "    from googleapiclient.discovery import build\n",
    "    import moviepy\n",
    "    from PIL import Image\n",
    "    import torch\n",
    "    import concurrent.futures\n",
    "    print(\"‚úÖ –í—Å–µ –º–æ–¥—É–ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ\")\n",
    "    \n",
    "    # –¢–µ—Å—Ç GPU –¥–ª—è Whisper\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"üöÄ GPU –≥–æ—Ç–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è Whisper\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Whisper –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ CPU\")\n",
    "        \nexcept ImportError as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-bot",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "# –†–∞–∑—Ä–µ—à–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ event loops –¥–ª—è Colab\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"ü§ñ –ó–∞–ø—É—Å–∫–∞–µ–º Telegram –±–æ—Ç–∞...\")\n",
    "print(\"–î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É 'Interrupt execution' –∏–ª–∏ Ctrl+C\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞\n",
    "!python run_bot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage-section"
   },
   "source": [
    "## üì± –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ—Ç–∞:\n",
    "\n",
    "1. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞** - –æ—Ç–ø—Ä–∞–≤—å—Ç–µ `/start`\n",
    "2. **–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã** (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):\n",
    "   - `/duration 30` - –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–ª–∏–ø–æ–≤ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö\n",
    "   - `/title –ú–æ–π –∑–∞–≥–æ–ª–æ–≤–æ–∫` - –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –≤–∏–¥–µ–æ\n",
    "   - `/subtitle –ü–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫` - –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –≤–∏–¥–µ–æ\n",
    "   - `/cookies` - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å cookies –¥–ª—è –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö –≤–∏–¥–µ–æ\n",
    "3. **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∏–¥–µ–æ**:\n",
    "   - –°—Å—ã–ª–∫—É –Ω–∞ YouTube –≤–∏–¥–µ–æ\n",
    "   - –ò–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ —Ñ–∞–π–ª\n",
    "4. **–ü–æ–ª—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç** - —Å—Å—ã–ª–∫–∏ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∫–ª–∏–ø—ã –≤ Google Drive\n",
    "\n",
    "## üç™ –†–∞–±–æ—Ç–∞ —Å Cookies –¥–ª—è –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö –≤–∏–¥–µ–æ:\n",
    "\n",
    "–ï—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å –ø—Ä–∏–≤–∞—Ç–Ω–æ–µ –∏–ª–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –≤–∏–¥–µ–æ:\n",
    "\n",
    "1. **–≠–∫—Å–ø–æ—Ä—Ç cookies –∏–∑ –±—Ä–∞—É–∑–µ—Ä–∞**:\n",
    "   - –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ \"Get cookies.txt LOCALLY\" –¥–ª—è Chrome/Firefox\n",
    "   - –ó–∞–π–¥–∏—Ç–µ –Ω–∞ YouTube –∏ –∞–≤—Ç–æ—Ä–∏–∑—É–π—Ç–µ—Å—å\n",
    "   - –ù–∞–∂–º–∏—Ç–µ –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∏ —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ cookies\n",
    "\n",
    "2. **–£—Å—Ç–∞–Ω–æ–≤–∫–∞ cookies –≤ –±–æ—Ç–µ**:\n",
    "   - –û—Ç–ø—Ä–∞–≤—å—Ç–µ –∫–æ–º–∞–Ω–¥—É `/cookies`\n",
    "   - –í—Å—Ç–∞–≤—å—Ç–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ cookies —Ñ–∞–π–ª–∞\n",
    "   - –ë–æ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç cookies –∏ —Å–º–æ–∂–µ—Ç —Å–∫–∞—á–∏–≤–∞—Ç—å –ø—Ä–∏–≤–∞—Ç–Ω—ã–µ –≤–∏–¥–µ–æ\n",
    "\n",
    "3. **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –ø–æ–ª—É—á–µ–Ω–∏—è cookies**:\n",
    "   - –ß–µ—Ä–µ–∑ DevTools –±—Ä–∞—É–∑–µ—Ä–∞ (F12 ‚Üí Application ‚Üí Cookies)\n",
    "   - –≠–∫—Å–ø–æ—Ä—Ç –∏–∑ –¥—Ä—É–≥–∏—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π –¥–ª—è cookies\n",
    "\n",
    "## üîß –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:\n",
    "\n",
    "- **–û—à–∏–±–∫–∞ —Ç–æ–∫–µ–Ω–∞**: –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å Telegram Bot Token\n",
    "- **–û—à–∏–±–∫–∞ Google Drive**: –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ OAuth —Ç–æ–∫–µ–Ω –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω\n",
    "- **–û—à–∏–±–∫–∞ ffmpeg**: –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —è—á–µ–π–∫—É —Å —É—Å—Ç–∞–Ω–æ–≤–∫–æ–π —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
    "- **Timeout**: –î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏\n",
    "- **–ü—Ä–∏–≤–∞—Ç–Ω–æ–µ –≤–∏–¥–µ–æ**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É `/cookies` –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ cookies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "monitoring-section"
   },
   "source": [
    "## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ª–æ–≥–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-logs"
   },
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# –ò—â–µ–º –ª–æ–≥ —Ñ–∞–π–ª—ã\n",
    "log_files = glob.glob('*.log')\n",
    "if log_files:\n",
    "    print(\"üìã –ù–∞–π–¥–µ–Ω–Ω—ã–µ –ª–æ–≥ —Ñ–∞–π–ª—ã:\")\n",
    "    for log_file in log_files:\n",
    "        print(f\"  - {log_file}\")\n",
    "        \n",
    "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ª–æ–≥–∞\n",
    "    latest_log = max(log_files, key=os.path.getctime)\n",
    "    print(f\"\\nüìÑ –ü–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å—Ç—Ä–æ–∫ –∏–∑ {latest_log}:\")\n",
    "    !tail -20 {latest_log}\nelse:\n",
    "    print(\"üìã –õ–æ–≥ —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "monitor-performance"
   },
   "outputs": [],
   "source": [
    "# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏\n",
    "import psutil\n",
    "import torch\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def show_system_stats():\n",
    "    \"\"\"–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–µ–∫—É—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∏—Å—Ç–µ–º—ã\"\"\"\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print(\"üìä –ú–û–ù–ò–¢–û–†–ò–ù–ì –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # CPU\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "    print(f\"üñ•Ô∏è  CPU: {cpu_percent:.1f}%\")\n",
    "    \n",
    "    # RAM\n",
    "    memory = psutil.virtual_memory()\n",
    "    ram_used = (memory.total - memory.available) / (1024**3)\n",
    "    ram_total = memory.total / (1024**3)\n",
    "    ram_percent = memory.percent\n",
    "    print(f\"üß† RAM: {ram_used:.1f}/{ram_total:.1f} GB ({ram_percent:.1f}%)\")\n",
    "    \n",
    "    # GPU\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_memory_used = torch.cuda.memory_allocated(0) / (1024**3)\n",
    "        gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        gpu_percent = (gpu_memory_used / gpu_memory_total) * 100\n",
    "        print(f\"üöÄ GPU: {gpu_memory_used:.1f}/{gpu_memory_total:.1f} GB ({gpu_percent:.1f}%)\")\n",
    "    else:\n",
    "        print(\"üöÄ GPU: –ù–µ–¥–æ—Å—Ç—É–ø–µ–Ω\")\n",
    "    \n",
    "    # –î–∏—Å–∫\n",
    "    disk = psutil.disk_usage('/')\n",
    "    disk_used = (disk.total - disk.free) / (1024**3)\n",
    "    disk_total = disk.total / (1024**3)\n",
    "    disk_percent = (disk_used / disk_total) * 100\n",
    "    print(f\"üíæ –î–∏—Å–∫: {disk_used:.1f}/{disk_total:.1f} GB ({disk_percent:.1f}%)\")\n",
    "    \n",
    "    # –ü—Ä–æ—Ü–µ—Å—Å—ã\n",
    "    python_processes = [p for p in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']) \n",
    "                       if 'python' in p.info['name'].lower()]\n",
    "    \n",
    "    if python_processes:\n",
    "        print(f\"\\nüêç Python –ø—Ä–æ—Ü–µ—Å—Å—ã: {len(python_processes)}\")\n",
    "        for proc in python_processes[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø 3\n",
    "            print(f\"   PID {proc.info['pid']}: CPU {proc.info['cpu_percent']:.1f}%, RAM {proc.info['memory_percent']:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n‚è∞ –û–±–Ω–æ–≤–ª–µ–Ω–æ: {time.strftime('%H:%M:%S')}\")\n",
    "    print(\"\\nüí° –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –Ω–∞–∂–º–∏—Ç–µ 'Interrupt execution'\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ (–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤—Ä—É—á–Ω—É—é)\n",
    "try:\n",
    "    while True:\n",
    "        show_system_stats()\n",
    "        time.sleep(5)  # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥\nexcept KeyboardInterrupt:\n",
    "    print(\"\\n‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-temp-files"
   },
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\n",
    "import os\n",
    "\n",
    "print(\"üìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:\")\n",
    "for item in os.listdir('.'):\n",
    "    if os.path.isfile(item):\n",
    "        size = os.path.getsize(item)\n",
    "        print(f\"  üìÑ {item} ({size} bytes)\")\n",
    "    else:\n",
    "        print(f\"  üìÅ {item}/\")\n",
    "\n",
    "# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞–ø–∫–∏\n",
    "temp_dirs = [d for d in os.listdir('.') if d.startswith('temp_')]\n",
    "if temp_dirs:\n",
    "    print(f\"\\nüóÇÔ∏è –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞–ø–∫–∏: {len(temp_dirs)}\")\n",
    "    for temp_dir in temp_dirs[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 5\n",
    "        files_count = len(os.listdir(temp_dir))\n",
    "        print(f\"  üìÅ {temp_dir}/ ({files_count} —Ñ–∞–π–ª–æ–≤)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup-section"
   },
   "source": [
    "## üßπ –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup-temp"
   },
   "outputs": [],
   "source": [
    "# –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "print(\"üßπ –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...\")\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞–ø–∫–∏\n",
    "temp_dirs = glob.glob('temp_*')\n",
    "for temp_dir in temp_dirs:\n",
    "    if os.path.isdir(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "        print(f\"  üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –ø–∞–ø–∫–∞: {temp_dir}\")\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –≤–∏–¥–µ–æ —Ñ–∞–π–ª—ã\n",
    "temp_videos = glob.glob('temp_video_*.mp4') + glob.glob('youtube_video_*.mp4')\n",
    "for temp_video in temp_videos:\n",
    "    if os.path.isfile(temp_video):\n",
    "        os.remove(temp_video)\n",
    "        print(f\"  üóëÔ∏è –£–¥–∞–ª–µ–Ω —Ñ–∞–π–ª: {temp_video}\")\n",
    "\n",
    "print(\"‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "setup-section",
    "config-section",
    "monitoring-section",
    "cleanup-section"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}