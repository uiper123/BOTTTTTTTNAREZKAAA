import os
import asyncio
import logging
import ffmpeg
import json
from pathlib import Path

logger = logging.getLogger(__name__)

class VideoEditor:
    def __init__(self):
        self.output_dir = Path("output")
        self.output_dir.mkdir(exist_ok=True)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è
        self.font_path = "Obelix Pro.ttf"  # –ü—É—Ç—å –∫ —à—Ä–∏—Ñ—Ç—É
        self.title_color = "red"
        self.subtitle_color = "red"
    
    def get_video_info(self, video_path: str) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∏–¥–µ–æ"""
        try:
            probe = ffmpeg.probe(video_path)
            video_stream = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)
            
            if not video_stream:
                raise ValueError("–í–∏–¥–µ–æ –ø–æ—Ç–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            
            duration = float(probe['format']['duration'])
            width = int(video_stream['width'])
            height = int(video_stream['height'])
            fps = eval(video_stream['r_frame_rate'])
            
            return {
                'duration': duration,
                'width': width,
                'height': height,
                'fps': fps
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∏–¥–µ–æ: {e}")
            raise
    
    async def extract_segment(self, input_path: str, output_path: str, start_time: float, duration: float) -> bool:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞ –≤–∏–¥–µ–æ"""
        try:
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(
                None,
                self._extract_segment_sync,
                input_path, output_path, start_time, duration
            )
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞: {e}")
            return False
    
    def _extract_segment_sync(self, input_path: str, output_path: str, start_time: float, duration: float):
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞"""
        (
            ffmpeg
            .input(input_path, ss=start_time, t=duration)
            .output(output_path, vcodec='libx264', acodec='aac')
            .overwrite_output()
            .run(quiet=True)
        )
    
    async def create_clips_parallel(self, video_path: str, clip_duration: int, subtitles: list, start_index: int = 0, config: dict = None, max_parallel: int = 4) -> list:
        """–ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û–ï —Å–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–ø–æ–≤ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPU"""
        try:
            video_info = self.get_video_info(video_path)
            total_duration = video_info['duration']
            
            # –ü–ª–∞–Ω–∏—Ä—É–µ–º –≤—Å–µ –∫–ª–∏–ø—ã –∑–∞—Ä–∞–Ω–µ–µ
            clip_tasks = []
            current_time = 0
            clip_index = start_index
            
            while current_time < total_duration:
                remaining_time = total_duration - current_time
                
                # –ï—Å–ª–∏ –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è –º–µ–Ω—å—à–µ –∑–∞–¥–∞–Ω–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                if remaining_time < clip_duration:
                    logger.info(f"–ü—Ä–æ–ø—É—â–µ–Ω –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫—É—Å–æ–∫: {remaining_time:.1f} —Å–µ–∫ < {clip_duration} —Å–µ–∫")
                    break
                
                clip_path = self.output_dir / f"clip_{clip_index:03d}.mp4"
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –≤ —Å–ø–∏—Å–æ–∫
                clip_tasks.append({
                    'input_path': video_path,
                    'output_path': str(clip_path),
                    'start_time': current_time,
                    'duration': clip_duration,
                    'subtitles': subtitles,
                    'clip_number': clip_index + 1,
                    'config': config
                })
                
                current_time += clip_duration
                clip_index += 1
            
            logger.info(f"üöÄ –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê: {len(clip_tasks)} –∫–ª–∏–ø–æ–≤, –º–∞–∫—Å. –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ: {max_parallel}")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–ª–∏–ø—ã –ø–∞–∫–µ—Ç–∞–º–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU
            clips = []
            semaphore = asyncio.Semaphore(max_parallel)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á
            
            async def process_clip_task(task):
                async with semaphore:
                    success = await self.create_styled_clip(
                        task['input_path'],
                        task['output_path'],
                        task['start_time'],
                        task['duration'],
                        task['subtitles'],
                        task['clip_number'],
                        task['config']
                    )
                    if success:
                        return task['output_path']
                    return None
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            results = await asyncio.gather(*[process_clip_task(task) for task in clip_tasks], return_exceptions=True)
            
            # –°–æ–±–∏—Ä–∞–µ–º —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for result in results:
                if isinstance(result, str):  # –£—Å–ø–µ—à–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    clips.append(result)
                elif isinstance(result, Exception):
                    logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª–∏–ø–∞: {result}")
            
            logger.info(f"‚úÖ –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û —Å–æ–∑–¥–∞–Ω–æ {len(clips)}/{len(clip_tasks)} –∫–ª–∏–ø–æ–≤")
            return clips
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª–∏–ø–æ–≤: {e}")
            return []

    async def create_clips(self, video_path: str, clip_duration: int, subtitles: list, start_index: int = 0, config: dict = None) -> list:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–ø–æ–≤ –∏–∑ –≤–∏–¥–µ–æ —Å–æ —Å—Ç—Ä–æ–≥–∏–º —Ç–∞–π–º–ª–∞–π–Ω–æ–º"""
        try:
            video_info = self.get_video_info(video_path)
            total_duration = video_info['duration']
            
            clips = []
            current_time = 0
            clip_index = start_index
            skipped_clips = 0
            
            while current_time < total_duration:
                end_time = current_time + clip_duration
                
                # –°–¢–†–û–ì–ò–ô –¢–ê–ô–ú–õ–ê–ô–ù: —Ç–æ–ª—å–∫–æ –∫–ª–∏–ø—ã —Ç–æ—á–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                remaining_time = total_duration - current_time
                
                # –ï—Å–ª–∏ –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è –º–µ–Ω—å—à–µ –∑–∞–¥–∞–Ω–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                if remaining_time < clip_duration:
                    logger.info(f"–ü—Ä–æ–ø—É—â–µ–Ω –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫—É—Å–æ–∫: {remaining_time:.1f} —Å–µ–∫ < {clip_duration} —Å–µ–∫ (—Å—Ç—Ä–æ–≥–∏–π —Ç–∞–π–º–ª–∞–π–Ω)")
                    skipped_clips += 1
                    break
                
                clip_path = self.output_dir / f"clip_{clip_index:03d}.mp4"
                
                # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–ø —Å —Ç–æ—á–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é
                success = await self.create_styled_clip(
                    video_path,
                    str(clip_path),
                    current_time,
                    clip_duration,  # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                    subtitles,
                    clip_index + 1,
                    config
                )
                
                if success:
                    clips.append(str(clip_path))
                    logger.info(f"–°–æ–∑–¥–∞–Ω –∫–ª–∏–ø {clip_index + 1}: {current_time:.1f}-{current_time + clip_duration:.1f} —Å–µ–∫ ({clip_duration} —Å–µ–∫)")
                    clip_index += 1
                else:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫–ª–∏–ø {clip_index + 1}")
                
                current_time += clip_duration
            
            # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            expected_clips = int(total_duration // clip_duration)
            logger.info(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–û–ó–î–ê–ù–ò–Ø –ö–õ–ò–ü–û–í:")
            logger.info(f"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ: {total_duration:.1f} —Å–µ–∫")
            logger.info(f"   –û–∂–∏–¥–∞–ª–æ—Å—å –∫–ª–∏–ø–æ–≤: {expected_clips}")
            logger.info(f"   –°–æ–∑–¥–∞–Ω–æ –∫–ª–∏–ø–æ–≤: {len(clips)}")
            logger.info(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ –∫–ª–∏–ø–æ–≤: {skipped_clips}")
            logger.info(f"   –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {len(clips)/expected_clips*100:.1f}%")
            
            return clips
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª–∏–ø–æ–≤: {e}")
            return []
    
    async def create_styled_clip(self, input_path: str, output_path: str, start_time: float, 
                               duration: float, subtitles: list, clip_number: int, config: dict = None) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–ª–∏–ø–∞"""
        try:
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(
                None,
                self._create_styled_clip_sync,
                input_path, output_path, start_time, duration, subtitles, clip_number, config
            )
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–ª–∏–ø–∞: {e}")
            return False
    
    def _create_styled_clip_sync(self, input_path: str, output_path: str, start_time: float,
                               duration: float, subtitles: list, clip_number: int, config: dict = None):
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–ª–∏–ø–∞ —Å GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º"""
        
        gpu_available = self._check_gpu_support()
        video_info = self.get_video_info(input_path)
        original_width = video_info['width']
        original_height = video_info['height']
        original_fps = video_info['fps']
        is_large_video = original_width >= 2160 or original_height >= 2160

        # --- –û–±—â–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è GPU –∏ CPU ---
        logger.info(f"üé¨ –û–ë–†–ê–ë–û–¢–ö–ê –ö–õ–ò–ü–ê {clip_number}:")
        logger.info(f"   üìê –ò—Å—Ö–æ–¥–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {original_width}x{original_height} ({original_height}p)")
        logger.info(f"   üéûÔ∏è  FPS: {original_fps}")
        logger.info(f"   üéØ –¶–µ–ª–µ–≤–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ: 1080x1920 (–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)")

        quality_type = "SD"
        if original_height >= 2160: quality_type = "4K Ultra HD"
        elif original_height >= 1440: quality_type = "2K/1440p"
        elif original_height >= 1080: quality_type = "Full HD 1080p"
        elif original_height >= 720: quality_type = "HD 720p"
        logger.info(f"   üèÜ –ö–∞—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ: {quality_type}")

        target_screen_width = 1080
        target_screen_height = 1920
        original_aspect = original_width / original_height
        target_aspect = target_screen_width / target_screen_height
        center_video_height = int(target_screen_height * 0.8)
        
        crop_needed = False
        if original_aspect > target_aspect:
            target_height = center_video_height
            target_width = int(target_height * original_aspect)
            crop_needed = target_width > target_screen_width
            if crop_needed:
                crop_width = target_screen_width
                crop_height = target_height
        else:
            target_height = center_video_height
            target_width = int(target_height * original_aspect)
        
        target_width -= target_width % 2
        target_height -= target_height % 2

        # --- –í—ã–±–æ—Ä –ø–∞–π–ø–ª–∞–π–Ω–∞: GPU –∏–ª–∏ CPU ---
        if gpu_available:
            logger.info(f"   üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º GPU-—É—Å–∫–æ—Ä–µ–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω")
            input_kwargs = {'ss': start_time, 't': duration, 'c:v': 'h264_cuvid'}
            main_video = ffmpeg.input(input_path, **input_kwargs)
            
            # –ü–∞–π–ø–ª–∞–π–Ω –¥–ª—è —Ä–∞–∑–º—ã—Ç–æ–≥–æ —Ñ–æ–Ω–∞ –Ω–∞ GPU
            blurred_bg = (
                main_video.video
                .filter('scale_npp', 1080, 1920, force_original_aspect_ratio='increase', interp_algo='bicubic')
                .filter('crop', 1080, 1920)
                .filter('gblur', sigma=20) # gblur –±—É–¥–µ—Ç –Ω–∞ CPU, ffmpeg-python –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç
            )

            # –ü–∞–π–ø–ª–∞–π–Ω –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –≤–∏–¥–µ–æ –Ω–∞ GPU
            main_scaled = (
                main_video.video
                .filter('scale_npp', target_width, target_height, interp_algo='lanczos' if is_large_video else 'bicubic')
            )
            if crop_needed:
                main_scaled = main_scaled.filter('crop', crop_width, crop_height, x='(iw-ow)/2', y='(ih-oh)/2')
            
            # –ù–∞–ª–æ–∂–µ–Ω–∏–µ. ffmpeg-python –¥–æ–ª–∂–µ–Ω —Å–∞–º —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è —Å hwdownload/hwupload
            video_with_bg = ffmpeg.filter([blurred_bg, main_scaled], 'overlay', x='(W-w)/2', y='(H-h)/2')

        else:
            logger.info(f"   üíª –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU-–ø–∞–π–ø–ª–∞–π–Ω")
            main_video = ffmpeg.input(input_path, ss=start_time, t=duration)
            
            blurred_bg = (
                main_video.video
                .filter('scale', 1080, 1920, force_original_aspect_ratio='increase')
                .filter('crop', 1080, 1920)
                .filter('gblur', sigma=20)
            )
            
            main_scaled = main_video.video.filter('scale', target_width, target_height, flags='lanczos' if is_large_video else 'bicubic')
            if crop_needed:
                main_scaled = main_scaled.filter('crop', crop_width, crop_height, x='(iw-ow)/2', y='(ih-oh)/2')

            video_with_bg = ffmpeg.filter([blurred_bg, main_scaled], 'overlay', x='(W-w)/2', y='(H-h)/2')

        # --- –û–±—â–∞—è —á–∞—Å—Ç—å –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–∞ –∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ (–Ω–∞ CPU) ---
        if config:
            title_template = config.get('title', '–§–†–ê–ì–ú–ï–ù–¢')
            subtitle_template = config.get('subtitle', '–ß–∞—Å—Ç—å')
            custom_title = config.get('custom_title', False)
            custom_subtitle = config.get('custom_subtitle', False)
        else:
            title_template, subtitle_template, custom_title, custom_subtitle = '–§–†–ê–ì–ú–ï–ù–¢', '–ß–∞—Å—Ç—å', False, False

        title_text = title_template if custom_title else f"{title_template} {clip_number}"
        subtitle_text = subtitle_template if custom_subtitle else f"{subtitle_template} {clip_number}"
        
        title_start_time = 8.0
        video_with_text = video_with_bg.drawtext(
            text=title_text, fontfile=self.font_path, fontsize=60, fontcolor=self.title_color,
            x='(w-text_w)/2', y='100', enable=f'between(t,{title_start_time},{duration})'
        ).drawtext(
            text=subtitle_text, fontfile=self.font_path, fontsize=80, fontcolor=self.subtitle_color,
            x='(w-text_w)/2', y='200', enable=f'between(t,{title_start_time},{duration})'
        )
        
        final_video = self._add_animated_subtitles(video_with_text, subtitles, start_time, duration)
        audio = main_video.audio
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤—ã–≤–æ–¥
        if gpu_available:
            final_video_scaled = final_video.filter('hwupload_cuda').filter('scale_npp', 1080, 1920)
            output_params = {
                'vcodec': 'h264_nvenc', 'acodec': 'aac', 'preset': 'p4', 'tune': 'hq', 'rc': 'vbr',
                'cq': 16, 'pix_fmt': 'yuv420p', 'gpu': 0, 'b:v': '12M', 'b:a': '192k',
                'maxrate': '18M', 'bufsize': '24M', 'threads': '0', 'bf': '4', 'refs': '4',
                'profile:v': 'high', 'level': '4.1'
            }
            ffmpeg.output(final_video_scaled, audio, output_path, **output_params).overwrite_output().run(quiet=True)
            logger.info(f"   ‚úÖ –ö–ª–∏–ø {clip_number} —Å–æ–∑–¥–∞–Ω —Å GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º (1080x1920)")
        else:
            final_video_scaled = final_video.filter('scale', 1080, 1920)
            output_params = {
                'vcodec': 'libx264', 'acodec': 'aac', 'preset': 'medium', 'crf': 20,
                'pix_fmt': 'yuv420p', 'profile': 'high', 'level': '4.1', 'b:a': '192k',
                'maxrate': '10M', 'bufsize': '15M', 'bf': '3', 'refs': '3'
            }
            ffmpeg.output(final_video_scaled, audio, output_path, **output_params).overwrite_output().run(quiet=True)
            logger.info(f"   ‚úÖ –ö–ª–∏–ø {clip_number} —Å–æ–∑–¥–∞–Ω —Å CPU (1080x1920)")
    
    def _add_animated_subtitles(self, video, subtitles: list, start_time: float, duration: float):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—É–±—Ç–∏—Ç—Ä–æ–≤"""
        if not subtitles:
            return video
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—É–±—Ç–∏—Ç—Ä—ã –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
        segment_subtitles = []
        for sub in subtitles:
            sub_start = sub['start'] - start_time
            sub_end = sub['end'] - start_time
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–ø–∞–¥–∞–µ—Ç –ª–∏ —Å—É–±—Ç–∏—Ç—Ä –≤ —Ç–µ–∫—É—â–∏–π —Å–µ–≥–º–µ–Ω—Ç
            if sub_end > 0 and sub_start < duration:
                # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞
                adjusted_start = max(0, sub_start)
                adjusted_end = min(duration, sub_end)
                
                segment_subtitles.append({
                    'text': sub['text'],
                    'start': adjusted_start,
                    'end': adjusted_end
                })
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–∂–¥—ã–π —Å—É–±—Ç–∏—Ç—Ä —Å –∞–Ω–∏–º–∞—Ü–∏–µ–π –ø–æ–¥–ø—Ä—ã–≥–∏–≤–∞–Ω–∏—è
        result_video = video
        for i, sub in enumerate(segment_subtitles):
            # –°–æ–∑–¥–∞–µ–º –∞–Ω–∏–º–∞—Ü–∏—é –ø–æ–¥–ø—Ä—ã–≥–∏–≤–∞–Ω–∏—è (–ø–æ–¥–Ω–∏–º–∞–µ–º –≤—ã—à–µ)
            bounce_y = f"h-600-20*sin(2*PI*t*3)"  # –ü–æ–¥–ø—Ä—ã–≥–∏–≤–∞–Ω–∏–µ –≤—ã—à–µ
            
            result_video = result_video.drawtext(
                text=sub['text'],
                fontfile=self.font_path if os.path.exists(self.font_path) else None,
                fontsize=70,  # –£–≤–µ–ª–∏—á–∏–ª —Ä–∞–∑–º–µ—Ä —Å—É–±—Ç–∏—Ç—Ä–æ–≤
                fontcolor='white',
                bordercolor='black',
                borderw=3,  # –£–≤–µ–ª–∏—á–∏–ª —Ç–æ–ª—â–∏–Ω—É –æ–±–≤–æ–¥–∫–∏
                x='(w-text_w)/2',
                y=bounce_y,
                enable=f"between(t,{sub['start']},{sub['end']})"
            )
        
        return result_video
    
    def _check_gpu_support(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ GPU –¥–ª—è ffmpeg"""
        try:
            import subprocess
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å NVENC (NVIDIA GPU –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫)
            result = subprocess.run(
                ['ffmpeg', '-hide_banner', '-encoders'], 
                capture_output=True, 
                text=True, 
                timeout=10
            )
            
            if 'h264_nvenc' in result.stdout:
                logger.info("‚úÖ GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞ (NVENC) –¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è ffmpeg")
                return True
            else:
                logger.info("‚ùå GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")
                return False
                
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ GPU: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")
            return False